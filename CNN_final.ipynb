{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ppxx\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\utils\\fixes.py:313: FutureWarning: numpy not_equal will not check object identity in the future. The comparison did not return the same result as suggested by the identity (`is`)) and will change.\n",
      "  _nan_object_mask = _nan_object_array != _nan_object_array\n",
      "C:\\Users\\ppxx\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\preprocessing\\data.py:323: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\ppxx\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:363: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "C:\\Users\\ppxx\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:363: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "C:\\Users\\ppxx\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:363: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "C:\\Users\\ppxx\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:363: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "C:\\Users\\ppxx\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:363: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "C:\\Users\\ppxx\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:363: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "C:\\Users\\ppxx\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:363: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "C:\\Users\\ppxx\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:363: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "C:\\Users\\ppxx\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:363: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "C:\\Users\\ppxx\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:363: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "#coding=utf-8\n",
    "import sys \n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import  accuracy_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "data = pd.read_csv('E:\\\\备份\\\\训练数据汇总(8W)\\\\2019_4_15.csv')\n",
    "data = data.loc[:, ~data.columns.str.contains('^Unnamed')]\n",
    "\n",
    "name = ['PHONE_VERSION', 'VIDEO_CLARITY']\n",
    "columns = data.columns.values.tolist()\n",
    "name_1 = [name for index, name in enumerate(columns) if name != name[0] and name != name[1]]\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X1 = data[name_1[0:16]]\n",
    "X1_data = scaler.fit_transform(X1)\n",
    "Y = data[name_1[16:21]]\n",
    "X2 = data[name[0]]\n",
    "X3 = data[name[1]]\n",
    "\n",
    "X2_data = OneHotEncoder().fit_transform(X2.values.reshape(-1, 1)).todense().getA()\n",
    "X3_data = OneHotEncoder().fit_transform(X3.values.reshape(-1, 1)).todense().getA()\n",
    "\n",
    "X_data = np.hstack((X1_data, X2_data, X3_data))\n",
    "\n",
    "Y1 = data[[name_1[16]]]\n",
    "Y2 = data[[name_1[17]]]\n",
    "Y3 = data[[name_1[18]]]\n",
    "Y4 = data[[name_1[19]]]\n",
    "\n",
    "[raw, col] = X_data.shape\n",
    "#shape = 8 * 8\n",
    "shape = 6 * 6\n",
    "X4_data = np.zeros([raw, shape - col])\n",
    "X_data = np.hstack((X_data, X4_data))\n",
    "\n",
    "X1_train, X1_test, y1_train, y1_test = train_test_split(X_data, Y1, test_size=0.25, random_state = 33)\n",
    "X2_train, X2_test, y2_train, y2_test = train_test_split(X_data, Y2, test_size=0.25, random_state = 33)\n",
    "X3_train, X3_test, y3_train, y3_test = train_test_split(X_data, Y3, test_size=0.25, random_state = 33)\n",
    "X4_train, X4_test, y4_train, y4_test = train_test_split(X_data, Y4, test_size=0.25, random_state = 33)\n",
    "\n",
    "X1_train = X1_train.reshape(-1 , 6, 6, 1)\n",
    "X1_test = X1_test.reshape(-1, 6 ,6 , 1)\n",
    "y1_train = OneHotEncoder().fit_transform(y1_train.values.reshape(-1, 1)).todense().getA()\n",
    "y1_test_code = OneHotEncoder().fit_transform(y1_test.values.reshape(-1, 1)).todense().getA()\n",
    "\n",
    "X2_train = X2_train.reshape(-1,6,6,1)\n",
    "X2_test = X2_test.reshape(-1,6,6,1)\n",
    "y2_train = OneHotEncoder().fit_transform(y2_train.values.reshape(-1, 1)).todense().getA()\n",
    "y2_test_code = OneHotEncoder().fit_transform(y2_test.values.reshape(-1, 1)).todense().getA()\n",
    "\n",
    "X3_train = X3_train.reshape(-1,6,6,1)\n",
    "X3_test = X3_test.reshape(-1,6,6,1)\n",
    "y3_train = OneHotEncoder().fit_transform(y3_train.values.reshape(-1, 1)).todense().getA()\n",
    "y3_test_code = OneHotEncoder().fit_transform(y3_test.values.reshape(-1, 1)).todense().getA()\n",
    "\n",
    "X4_train = X4_train.reshape(-1,6,6,1)\n",
    "X4_test = X4_test.reshape(-1,6,6,1)\n",
    "y4_train = OneHotEncoder().fit_transform(y4_train.values.reshape(-1, 1)).todense().getA()\n",
    "y4_test_code = OneHotEncoder().fit_transform(y4_test.values.reshape(-1, 1)).todense().getA()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generatebatch(X,Y,n_examples, batch_size): \n",
    "    for batch_i in range(n_examples // batch_size): \n",
    "        start = batch_i * batch_size \n",
    "        end = start + batch_size \n",
    "        batch_xs = X[start:end] \n",
    "        batch_ys = Y[start:end] \n",
    "        yield batch_xs, batch_ys \n",
    "        \n",
    "# 使用MBGD算法，设定batch_size为8\n",
    "batch_size = 1024\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# 输入层\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "tf_X = tf.placeholder(tf.float32,[None,6,6,1])\n",
    "tf_Y = tf.placeholder(tf.float32,[None,5])\n",
    "\n",
    "# 卷积层+激活层 \n",
    "conv_filter_w1 = tf.Variable(tf.random_normal([3, 3, 1, 5])) \n",
    "conv_filter_b1 = tf.Variable(tf.random_normal([5])) \n",
    "relu_feature_maps1 = tf.nn.relu(tf.nn.conv2d(tf_X, conv_filter_w1, strides=[1, 1, 1, 1], padding='SAME') + conv_filter_b1)\n",
    "\n",
    "# 池化层\n",
    "max_pool1 = tf.nn.max_pool(relu_feature_maps1, ksize = [1,3,3,1], strides = [1,2,2,1], padding = 'SAME')\n",
    "\n",
    "# 卷积层 \n",
    "conv_filter_w2 = tf.Variable(tf.random_normal([3, 3, 5, 5])) \n",
    "conv_filter_b2 = tf.Variable(tf.random_normal([5])) \n",
    "conv_out2 = tf.nn.conv2d(relu_feature_maps1, conv_filter_w2, strides = [1, 2, 2, 1], padding = 'SAME') + conv_filter_b2 \n",
    "\n",
    "# BN归一化层+激活层 \n",
    "batch_mean, batch_var = tf.nn.moments(conv_out2, [0, 1, 2], keep_dims = True) \n",
    "shift = tf.Variable(tf.zeros([5])) \n",
    "scale = tf.Variable(tf.ones([5])) \n",
    "epsilon = 1e-3 \n",
    "BN_out = tf.nn.batch_normalization(conv_out2, batch_mean, batch_var, shift, scale, epsilon) \n",
    "relu_BN_maps2 = tf.nn.relu(BN_out)\n",
    "\n",
    "# 池化层\n",
    "max_pool2 = tf.nn.max_pool(relu_BN_maps2, ksize = [1,3,3,1], strides = [1,2,2,1], padding = 'SAME')\n",
    "\n",
    "# 将特征图进行展开\n",
    "max_pool2_flat = tf.reshape(max_pool2, [-1, 2*2*5])\n",
    "\n",
    "# 全连接层 \n",
    "fc_w1 = tf.Variable(tf.random_normal([2*2*5,50])) \n",
    "fc_b1 = tf.Variable(tf.random_normal([50])) \n",
    "fc_out1 = tf.nn.relu(tf.matmul(max_pool2_flat, fc_w1) + fc_b1)\n",
    "fc_out1 = tf.nn.dropout(fc_out1, keep_prob)\n",
    "\n",
    "# 输出层 \n",
    "out_w1 = tf.Variable(tf.random_normal([50,5])) \n",
    "out_b1 = tf.Variable(tf.random_normal([5])) \n",
    "pred = tf.nn.softmax(tf.matmul(fc_out1, out_w1)+out_b1)\n",
    "\n",
    "loss = -1*tf.reduce_mean(tf_Y*tf.log(tf.clip_by_value(pred, 1e-11, 1.0)))\n",
    "train_step = tf.train.AdamOptimizer(1e-3).minimize(loss)\n",
    "\n",
    "y_pred = tf.argmax(pred, 1)\n",
    "bool_pred = tf.equal(tf.argmax(tf_Y,1), y_pred)\n",
    "# 准确率\n",
    "accuracy = tf.reduce_mean(tf.cast(bool_pred, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######### The train & test process of SCORE1 ##########\n",
      "The 0 epoch, the accuracy is 0.145403 \n",
      "The 100 epoch, the accuracy is 0.763593 \n",
      "The 200 epoch, the accuracy is 0.763647 \n",
      "The 300 epoch, the accuracy is 0.763620 \n",
      "The 400 epoch, the accuracy is 0.763863 \n",
      "The 500 epoch, the accuracy is 0.764133 \n",
      "The 600 epoch, the accuracy is 0.763782 \n",
      "The 700 epoch, the accuracy is 0.763782 \n",
      "The 800 epoch, the accuracy is 0.763890 \n",
      "The 900 epoch, the accuracy is 0.763971 \n",
      "The result of the test bath is   [4 4 4 ..., 4 4 4]\n",
      "The accurate score of the test bath is   0.14439585358\n",
      "The MSE of the test bach is   0.890022675737\n",
      "######### The train & test process of SCORE2 ##########\n",
      "The 0 epoch, the accuracy is 0.758355 \n",
      "The 100 epoch, the accuracy is 0.758355 \n",
      "The 200 epoch, the accuracy is 0.758436 \n",
      "The 300 epoch, the accuracy is 0.758328 \n",
      "The 400 epoch, the accuracy is 0.758382 \n",
      "The 500 epoch, the accuracy is 0.758436 \n",
      "The 600 epoch, the accuracy is 0.758517 \n",
      "The 700 epoch, the accuracy is 0.758463 \n",
      "The 800 epoch, the accuracy is 0.758463 \n",
      "The 900 epoch, the accuracy is 0.758436 \n",
      "The result of the test bath is   [4 4 4 ..., 4 4 4]\n",
      "The accurate score of the test bath is   0.153871072238\n",
      "The MSE of the test bach is   0.879170715905\n",
      "######### The train & test process of SCORE3 ##########\n",
      "The 0 epoch, the accuracy is 0.785001 \n",
      "The 100 epoch, the accuracy is 0.833675 \n",
      "The 200 epoch, the accuracy is 0.833675 \n",
      "The 300 epoch, the accuracy is 0.833675 \n",
      "The 400 epoch, the accuracy is 0.833675 \n",
      "The 500 epoch, the accuracy is 0.833702 \n",
      "The 600 epoch, the accuracy is 0.833702 \n",
      "The 700 epoch, the accuracy is 0.833702 \n",
      "The 800 epoch, the accuracy is 0.833702 \n",
      "The 900 epoch, the accuracy is 0.833702 \n",
      "The accurate of the train bath is   [4 4 4 ..., 4 4 4]\n",
      "The accurate score of the test bath is   0.110301263362\n",
      "The MSE of the test bach is   0.904033041788\n",
      "######### The train & test process of SCORE4 ##########\n",
      "The 0 epoch, the accuracy is 0.334971 \n",
      "The 100 epoch, the accuracy is 0.751093 \n",
      "The 200 epoch, the accuracy is 0.751093 \n",
      "The 300 epoch, the accuracy is 0.751093 \n",
      "The 400 epoch, the accuracy is 0.751093 \n",
      "The 500 epoch, the accuracy is 0.751093 \n",
      "The 600 epoch, the accuracy is 0.751093 \n",
      "The 700 epoch, the accuracy is 0.751093 \n",
      "The 800 epoch, the accuracy is 0.751093 \n",
      "The 900 epoch, the accuracy is 0.751093 \n",
      "The result of the test bath is   [4 4 4 ..., 4 4 4]\n",
      "The accurate score of the test bath is   0.168691286038\n",
      "The MSE of the test bach is   0.836653709103\n"
     ]
    }
   ],
   "source": [
    "print(\"######### The train & test process of SCORE1 ##########\")\n",
    "with tf.Session() as sess: \n",
    "    sess.run(tf.global_variables_initializer()) \n",
    "    for epoch in range(1000): \n",
    "        # 迭代1000个周期 \n",
    "        for batch_xs,batch_ys in generatebatch(X1_train, y1_train, y1_train.shape[0], batch_size): \n",
    "            # 每个周期进行MBGD算法 \n",
    "            sess.run(train_step, feed_dict={tf_X:batch_xs, tf_Y:batch_ys, keep_prob: 0.5}) \n",
    "        if(epoch%100==0): \n",
    "            res = sess.run(accuracy,feed_dict={tf_X:X1_train, tf_Y:y1_train, keep_prob: 0.5}) \n",
    "            #print((epoch,res))\n",
    "            print(\"The %d epoch, the accuracy is %f \" %(epoch, res))\n",
    "    res_ypred = y_pred.eval(feed_dict={tf_X:X1_test, tf_Y:y1_test_code, keep_prob: 1}).flatten() \n",
    "    # 只能预测一批样本，不能预测一个样本 \n",
    "    print('The result of the test bath is  ', res_ypred)\n",
    "print(\"The accurate score of the test bath is  \", accuracy_score(y1_test, res_ypred.reshape(-1, 1)))\n",
    "print(\"The MSE of the test bach is  \",  mean_squared_error(y1_test, res_ypred.reshape(-1, 1)))\n",
    "\n",
    "print(\"######### The train & test process of SCORE2 ##########\")\n",
    "with tf.Session() as sess: \n",
    "    sess.run(tf.global_variables_initializer()) \n",
    "    for epoch in range(1000): \n",
    "        # 迭代1000个周期 \n",
    "        for batch_xs,batch_ys in generatebatch(X2_train, y2_train, y2_train.shape[0], batch_size): \n",
    "            # 每个周期进行MBGD算法 \n",
    "            sess.run(train_step, feed_dict={tf_X:batch_xs, tf_Y:batch_ys, keep_prob: 0.5}) \n",
    "        if(epoch%100==0): \n",
    "            res = sess.run(accuracy,feed_dict={tf_X:X2_train, tf_Y:y2_train, keep_prob: 1}) \n",
    "            #print((epoch,res))\n",
    "            print(\"The %d epoch, the accuracy is %f \" %(epoch, res))\n",
    "    res_ypred = y_pred.eval(feed_dict={tf_X:X2_test, tf_Y:y2_test_code, keep_prob: 1}).flatten() \n",
    "    # 只能预测一批样本，不能预测一个样本 \n",
    "    print('The result of the test bath is  ', res_ypred)\n",
    "print(\"The accurate score of the test bath is  \", accuracy_score(y2_test, res_ypred.reshape(-1, 1)))\n",
    "print(\"The MSE of the test bach is  \",  mean_squared_error(y2_test, res_ypred.reshape(-1, 1)))\n",
    "\n",
    "print(\"######### The train & test process of SCORE3 ##########\")\n",
    "with tf.Session() as sess: \n",
    "    sess.run(tf.global_variables_initializer()) \n",
    "    for epoch in range(1000): \n",
    "        # 迭代1000个周期 \n",
    "        for batch_xs,batch_ys in generatebatch(X3_train, y3_train, y3_train.shape[0], batch_size): \n",
    "            # 每个周期进行MBGD算法 \n",
    "            sess.run(train_step, feed_dict={tf_X:batch_xs, tf_Y:batch_ys, keep_prob: 0.5}) \n",
    "        if(epoch%100==0): \n",
    "            res = sess.run(accuracy,feed_dict={tf_X:X3_train, tf_Y:y3_train, keep_prob: 1}) \n",
    "            #print((epoch,res))\n",
    "            print(\"The %d epoch, the accuracy is %f \" %(epoch, res))\n",
    "    res_ypred = y_pred.eval(feed_dict={tf_X:X3_test, tf_Y:y3_test_code, keep_prob: 1}).flatten() \n",
    "    # 只能预测一批样本，不能预测一个样本 \n",
    "    print('The accurate of the train bath is  ', res_ypred)\n",
    "print(\"The accurate score of the test bath is  \", accuracy_score(y3_test, res_ypred.reshape(-1, 1)))\n",
    "print(\"The MSE of the test bach is  \",  mean_squared_error(y3_test, res_ypred.reshape(-1, 1)))\n",
    "\n",
    "print(\"######### The train & test process of SCORE4 ##########\")\n",
    "with tf.Session() as sess: \n",
    "    sess.run(tf.global_variables_initializer()) \n",
    "    for epoch in range(1000): \n",
    "        # 迭代1000个周期 \n",
    "        for batch_xs,batch_ys in generatebatch(X4_train, y4_train, y4_train.shape[0], batch_size): \n",
    "            # 每个周期进行MBGD算法 \n",
    "            sess.run(train_step, feed_dict={tf_X:batch_xs, tf_Y:batch_ys, keep_prob: 0.5}) \n",
    "        if(epoch%100==0): \n",
    "            res = sess.run(accuracy,feed_dict={tf_X:X4_train, tf_Y:y4_train, keep_prob: 1}) \n",
    "            #print((epoch,res))\n",
    "            print(\"The %d epoch, the accuracy is %f \" %(epoch, res))\n",
    "    res_ypred = y_pred.eval(feed_dict={tf_X:X4_test, tf_Y:y4_test_code, keep_prob: 1}).flatten() \n",
    "    # 只能预测一批样本，不能预测一个样本 \n",
    "    print('The result of the test bath is  ', res_ypred)\n",
    "print(\"The accurate score of the test bath is  \", accuracy_score(y4_test, res_ypred.reshape(-1, 1)))\n",
    "print(\"The MSE of the test bach is  \",  mean_squared_error(y4_test, res_ypred.reshape(-1, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "Counter(res_ypred.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
