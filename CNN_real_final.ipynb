{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import sys \n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "from collections import Counter\n",
    "from sklearn.metrics import  accuracy_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "def generatebatch(X,Y,n_examples, batch_size): \n",
    "    for batch_i in range(n_examples // batch_size): \n",
    "        start = batch_i * batch_size \n",
    "        end = start + batch_size \n",
    "        batch_xs = X[start:end] \n",
    "        batch_ys = Y[start:end] \n",
    "        yield batch_xs, batch_ys \n",
    "    \n",
    "data = pd.read_csv('E:\\\\备份\\\\训练数据汇总(8W)\\\\2019_4_15.csv')\n",
    "data = data.loc[:, ~data.columns.str.contains('^Unnamed')]\n",
    "\n",
    "name = ['PHONE_VERSION', 'VIDEO_CLARITY']\n",
    "columns = data.columns.values.tolist()\n",
    "name_1 = [name for index, name in enumerate(columns) if name != name[0] \n",
    "          and name != name[1]]\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X1 = data[name_1[0:16]]\n",
    "X1_data = scaler.fit_transform(X1)\n",
    "Y = data[name_1[16:21]]\n",
    "X2 = data[name[0]]\n",
    "X3 = data[name[1]]\n",
    "\n",
    "X2_data = OneHotEncoder().fit_transform(X2.values.reshape(-1, 1)).todense().getA()\n",
    "X3_data = OneHotEncoder().fit_transform(X3.values.reshape(-1, 1)).todense().getA()\n",
    "\n",
    "X_data = np.hstack((X1_data, X2_data, X3_data))\n",
    "\n",
    "Y1 = data[[name_1[16]]]\n",
    "Y2 = data[[name_1[17]]]\n",
    "Y3 = data[[name_1[18]]]\n",
    "Y4 = data[[name_1[19]]]\n",
    "\n",
    "smo = SMOTE(random_state=42)\n",
    "X1_smo, y1_smo = smo.fit_sample(X_data, Y1)\n",
    "\n",
    "smo = SMOTE(random_state=42)\n",
    "X2_smo, y2_smo = smo.fit_sample(X_data, Y2)\n",
    "\n",
    "smo = SMOTE(random_state=42)\n",
    "X3_smo, y3_smo = smo.fit_sample(X_data, Y3)\n",
    "\n",
    "smo = SMOTE(random_state=42)\n",
    "X4_smo, y4_smo = smo.fit_sample(X_data, Y4)\n",
    "\n",
    "X1_train, X1_test, y1_train, y1_test = train_test_split(X1_smo, y1_smo, \n",
    "                                                        test_size=0.25, \n",
    "                                                        random_state = 33)\n",
    "X2_train, X2_test, y2_train, y2_test = train_test_split(X2_smo, y2_smo, \n",
    "                                                        test_size=0.25, \n",
    "                                                        random_state = 33)\n",
    "X3_train, X3_test, y3_train, y3_test = train_test_split(X3_smo, y3_smo, \n",
    "                                                        test_size=0.25, \n",
    "                                                        random_state = 33)\n",
    "X4_train, X4_test, y4_train, y4_test = train_test_split(X4_smo, y4_smo, \n",
    "                                                        test_size=0.25, \n",
    "                                                        random_state = 33)\n",
    "X1_train = X1_train.reshape(-1 ,1, 4, 7)\n",
    "X1_test = X1_test.reshape(-1, 1 ,4,7 )\n",
    "y1_train = OneHotEncoder().fit_transform(y1_train.reshape(-1, 1)).todense().getA()\n",
    "y1_test_code = OneHotEncoder().fit_transform(y1_test.reshape(-1, 1)).todense().getA()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######### The train & test process of SCORE1 ##########\n",
      "The 0 epoch, the accuracy is 0.341475 \n",
      "The 100 epoch, the accuracy is 0.437777 \n",
      "The 200 epoch, the accuracy is 0.453246 \n",
      "The 300 epoch, the accuracy is 0.460920 \n",
      "The 400 epoch, the accuracy is 0.466070 \n",
      "The 500 epoch, the accuracy is 0.475116 \n"
     ]
    }
   ],
   "source": [
    "# 使用MBGD算法，设定batch_size为8\n",
    "batch_size = 1024\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# 输入层\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "tf_X = tf.placeholder(tf.float32,[None,1,4,7])\n",
    "tf_Y = tf.placeholder(tf.float32,[None,5])\n",
    "\n",
    "# 卷积层+激活层 \n",
    "relu_feature_maps1 = tf.nn.relu(tf.layers.conv2d(tf_X,\n",
    "                                                 kernel_size=[3,3],\n",
    "                                                 strides=[1,1],\n",
    "                                                 filters=5, \n",
    "                                                 padding = 'SAME'))\n",
    "relu_feature_maps2 = tf.nn.relu(tf.layers.conv2d(relu_feature_maps1,\n",
    "                                                 kernel_size=[2,2],\n",
    "                                                 strides=[1,1],\n",
    "                                                 filters=5, \n",
    "                                                 padding = 'SAME'))\n",
    "\n",
    "max_pool2_flat = tf.reshape(relu_feature_maps2, [-1,5*1*4])\n",
    "fc1 = tf.layers.dense(max_pool2_flat,units=50,activation=tf.nn.relu)\n",
    "\n",
    "fc2 = tf.layers.dense(fc1,units=5,activation=tf.nn.relu)\n",
    "\n",
    "pred = tf.nn.softmax(fc2)\n",
    "\n",
    "loss = -1*tf.reduce_mean(tf_Y*tf.log(tf.clip_by_value(pred, 1e-11, 1.0)))\n",
    "train_step = tf.train.AdamOptimizer(1e-3).minimize(loss)\n",
    "\n",
    "y_pred = tf.argmax(pred, 1)\n",
    "bool_pred = tf.equal(tf.argmax(tf_Y,1), y_pred)\n",
    "# 准确率\n",
    "accuracy = tf.reduce_mean(tf.cast(bool_pred, tf.float32))\n",
    "\n",
    "print(\"######### The train & test process of SCORE1 ##########\")\n",
    "with tf.Session() as sess: \n",
    "    sess.run(tf.global_variables_initializer()) \n",
    "    for epoch in range(1000): \n",
    "        # 迭代1000个周期 \n",
    "        for batch_xs,batch_ys in generatebatch(X1_train, \n",
    "                                               y1_train, \n",
    "                                               y1_train.shape[0], \n",
    "                                               batch_size): \n",
    "            # 每个周期进行MBGD算法 \n",
    "            sess.run(train_step, feed_dict={tf_X:batch_xs, \n",
    "                                            tf_Y:batch_ys, \n",
    "                                            keep_prob: 0.5}) \n",
    "        if(epoch%100==0): \n",
    "            res = sess.run(accuracy,feed_dict={tf_X:X1_train, \n",
    "                                               tf_Y:y1_train, \n",
    "                                               keep_prob: 0.5}) \n",
    "            #print((epoch,res))\n",
    "            print(\"The %d epoch, the accuracy is %f \" %(epoch, res))\n",
    "    res_ypred = y_pred.eval(feed_dict={tf_X:X1_test, \n",
    "                                       tf_Y:y1_test_code, \n",
    "                                       keep_prob: 1}).flatten() \n",
    "    # 只能预测一批样本，不能预测一个样本 \n",
    "    print('The result of the test bath is  ', res_ypred)\n",
    "print(\"The accurate score of the test bath is  \", \n",
    "      accuracy_score(y1_test, res_ypred.reshape(-1, 1)))\n",
    "print(\"The MSE of the test bach is  \",  \n",
    "      mean_squared_error(y1_test, res_ypred.reshape(-1, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
